import re
from dataclasses import field
from typing import Any, TYPE_CHECKING
from distilabel.mixins.runtime_parameters import RuntimeParameter
from pydantic import Field
from qatch.connectors.base_connector import ConnectorTable
from typing_extensions import override

from distilabel.steps import GeneratorStep

if TYPE_CHECKING:
    from distilabel.typing import StepColumns, GeneratorStepOutput

from qatch.connectors import SqliteConnector


class LoadSqliteDatabase(GeneratorStep):
    """A special kind of `Step` that is able to generate data i.e. it doesn't receive
    any input from the previous steps.

    Attributes:
        db_id: The id of the database. If not provided, it will be set to the name of the db_path
        db_path: The path to the SQLite database file.
        tables: The tables loaded from the SQLite database. It is a list of dictionaries.

    Notes:
        This step is used to load a SQLite database and generate data from it.
        The tables are loaded into a list of dictionaries where each dictionary represents a
        table and its columns. The keys of the dictionary:
        - `db_path`: The path to the SQLite database file.
        - `db_id`: The id of the database. If not provided, it will be set to the name of the db_path.
        - `db_schema`: The schema of the database.
        - `db_schema_table`: The schema of the table with examples.
        - `db_schema_table_examples`: The schema of the table with examples.
        - `tbl_name`: The name of the table.
        - `tbl_col2metadata`: A dictionary mapping from table column names to their metadata.
            - `column_name`: The column name in the table.
            - `column_type`: The datatype of the column, can be either 'categorical' or 'numerical'.
            - `sample_data`: A list of sample data values from the column.
        - `cat_col2metadata`: A dictionary mapping from category column names to their metadata.
        - `num_col2metadata`: A dictionary mapping from numeric column names to their metadata.
        - `primary_key`: The primary keys of the table as list of dict.
            - `column_name`: The column name in the table.
            - `column_type`: The datatype of the column, can be either 'categorical' or 'numerical'.
            - `sample_data`: A list of sample data values from the column.
        - `foreign_keys`: A list of foreign keys in the table.
            - `parent_column`: The name of the parent column involved in the foreign key relationship.
            - `child_column`: The name of the child column involved in the foreign key relationship.
            - `child_table`: The child table object in the foreign key relationship.

    Runtime parameters:
        - `batch_size`: The number of rows that will contain the batches generated by
            the step. Defaults to `50`.
    """

    db_path: str
    db_id: str | None = field(default=None)
    tables: list[dict] | None = field(default=None)
    batch_size: RuntimeParameter[int] = Field(
        default=1,
        description="The number of table to process for each batch",
    )

    def model_post_init(self, __context: Any) -> None:
        super().model_post_init(__context)
        self.db_id = self.db_id or self.db_path.split("/")[-1].split(".")[0]
        self.db_id = self.db_id or self.db_path.split("/")[-1].split(".")[0]
        self.tables = self._load_qatch()

    @override
    def process(self, offset: int = 0) -> "GeneratorStepOutput":
        """Method that defines the generation logic of the step. It should yield the
        output rows and a boolean indicating if it's the last batch or not.

        Args:
            offset: The offset to start the generation from. Defaults to 0.

        Yields:
            The output rows and a boolean indicating if it's the last batch or not.
        """
        if offset:
            self.tables = self.tables[offset:]

        while self.tables:
            batch = [
                {
                    "table": table,
                    "db_id": table["db_id"],
                    "db_path": self.db_path,
                    "db_schema": table["db_schema"],
                    "db_schema_table": table["db_schema_table"],
                    "db_schema_table_examples": table["db_schema_table_examples"],
                    "tbl_name": table["tbl_name"],
                }
                for table in self.tables[:1]
            ]
            self.tables = self.tables[self.batch_size :]
            yield (
                batch,
                True if len(self.tables) == 0 else False,
            )

    @property
    def outputs(self) -> "StepColumns":
        return [
            "table",
            "db_id",
            "db_path",
            "db_schema",
            "db_schema_table",
            "tbl_name",
            "db_schema_table_examples",
        ]

    def _load_qatch(self):
        db_uri = f"file:{self.db_path}?immutable=1&uri=true"
        connector = SqliteConnector(
            relative_db_path=db_uri,
            db_name=self.db_id,
        )
        tbl_name2table: dict[str, ConnectorTable] = (
            connector.load_tables_from_database()
        )

        tables = [val.model_dump() for val in tbl_name2table.values()]
        for val in tables:
            val["db_id"] = val.pop("db_name", None)
            val["db_schema_table"] = connector.run_query(
                f"SELECT sql FROM sqlite_master WHERE type='table' AND name='{val['tbl_name']}'"
            )[0][0]
            val["db_schema_table_examples"] = (
                self._create_database_schema_with_examples(val, val["db_schema_table"])
            )

            val["db_schema"] = "\n".join(
                [val[0] for val in connector.run_query("SELECT sql FROM sqlite_master")]
            )

            for col_name in val["foreign_keys"]:
                col_name["parent_column"] = str(col_name["parent_column"])

        return tables

    def _create_database_schema_with_examples(
        self, table: dict, tbl_schema: str
    ) -> str:
        """
        Insert example values as comments for each column in the dumped schema.
        """
        col_metadata = table["tbl_col2metadata"]
        lines = []
        for line in tbl_schema.split(","):
            stripped = line.strip()
            # Try to match column definitions (skip lines that start with CREATE TABLE, constraints, etc.)
            if (
                stripped
                and not stripped.upper().startswith("PRIMARY KEY")
                and not stripped.upper().startswith("FOREIGN KEY")
            ):
                columns_in_line = re.findall(
                    r"[`'\"]?(\w+)[`'\"]?\s+\w+", stripped, re.IGNORECASE
                )
                for col_name in columns_in_line:
                    meta = col_metadata.get(col_name, None)
                    if meta:
                        sample_data = meta.get("sample_data", [])
                        sample_str = ", ".join(
                            [f"`{str(val)}`" for val in sample_data[:2]]
                        )
                        if sample_str:
                            line = line.rstrip() + f" -- Example Values: ({sample_str})"
            lines.append(line)
        return ",\n".join(lines)
